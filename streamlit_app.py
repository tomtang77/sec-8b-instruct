import streamlit as st
import sys
import os

# ç‚ºäº†é¿å…å°å…¥app_chat.pyæ™‚åŸ·è¡Œåº•éƒ¨çš„èŠå¤©å¾ªç’°ï¼Œæˆ‘å€‘ç›´æ¥è¤‡è£½éœ€è¦çš„ä»£ç¢¼
import transformers
import torch
import re
import os

# export Huggfing Face token to HF_TOKEN
HF_TOKEN = os.getenv("HF_TOKEN")

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

MODEL_ID = "fdtn-ai/Foundation-Sec-8B-Instruct"

from transformers import AutoModelForCausalLM, AutoTokenizer

# åªæœ‰åœ¨é‚„æ²’æœ‰è¼‰å…¥æ¨¡å‹æ™‚æ‰è¼‰å…¥ï¼ˆé¿å…é‡è¤‡è¼‰å…¥ï¼‰
if 'tokenizer' not in st.session_state:
    with st.spinner("ğŸ”„ æ­£åœ¨è¼‰å…¥æ¨¡å‹..."):
        st.session_state.tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)
        st.session_state.model = AutoModelForCausalLM.from_pretrained(
            pretrained_model_name_or_path=MODEL_ID,
            device_map="auto",
            torch_dtype=torch.bfloat16,
            token=HF_TOKEN,
        )

generation_args = {
    "max_new_tokens": 1024,
    "temperature": None,
    "repetition_penalty": 1.2,
    "do_sample": False,
    "use_cache": True,
    "eos_token_id": st.session_state.tokenizer.eos_token_id,
    "pad_token_id": st.session_state.tokenizer.pad_token_id,
}

DEFAULT_SYSTEM_PROMPT = "You are a cybersecurity expert."

def inference(request, system_prompt=DEFAULT_SYSTEM_PROMPT):
    if isinstance(request, str):
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": request},
        ]
    elif isinstance(request, list):
        if request[0].get("role") != "system":
            messages = [{"role": "system", "content": system_prompt}] + request
        else:
            messages = request
    else:
        raise ValueError(
            "Request is not well formed. It must be a string or list of dict with correct format."
        )

    inputs = st.session_state.tokenizer.apply_chat_template(
        messages, tokenize=False, add_generation_prompt=True
    )
    
    inputs = st.session_state.tokenizer(inputs, return_tensors="pt")
    input_ids = inputs["input_ids"].to(DEVICE)
    with torch.no_grad():
        outputs = st.session_state.model.generate(
            input_ids=input_ids,
            **generation_args,
        )
    response = st.session_state.tokenizer.decode(
        outputs[0][input_ids.shape[1]:],  # Only get new tokens
        skip_special_tokens=False
    )
    
    if response.endswith(st.session_state.tokenizer.eos_token):
        response = response[:-len(st.session_state.tokenizer.eos_token)]
    
    return response

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="ğŸ¤– Cybersecurity Expert Chat",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–session state
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": DEFAULT_SYSTEM_PROMPT}]

if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = DEFAULT_SYSTEM_PROMPT

# å´é‚Šæ¬„è¨­å®š
with st.sidebar:
    st.title("âš™ï¸ è¨­å®š")
    
    # ç³»çµ±æç¤ºè©è¨­å®š
    # new_system_prompt = st.text_area(
    #     "ç³»çµ±æç¤ºè©", 
    #     value=st.session_state.system_prompt,
    #     height=100,
    #     help="è¨­å®šAIåŠ©æ‰‹çš„è§’è‰²å’Œè¡Œç‚º"
    # )
    
    # if st.button("ğŸ”„ æ›´æ–°ç³»çµ±æç¤ºè©"):
    #     st.session_state.system_prompt = new_system_prompt
    #     st.session_state.messages[0] = {"role": "system", "content": new_system_prompt}
    #     st.success("ç³»çµ±æç¤ºè©å·²æ›´æ–°ï¼")
    #     st.rerun()
    
    # st.divider()
    
    # å°è©±ç®¡ç†æŒ‰éˆ•
    if st.button("ğŸ§¹ æ¸…é™¤å°è©±æ­·å²", type="secondary"):
        st.session_state.messages = [{"role": "system", "content": st.session_state.system_prompt}]
        st.success("å°è©±æ­·å²å·²æ¸…é™¤ï¼")
        st.rerun()
    
    # é¡¯ç¤ºå°è©±çµ±è¨ˆ
    user_messages = [msg for msg in st.session_state.messages if msg["role"] == "user"]
    assistant_messages = [msg for msg in st.session_state.messages if msg["role"] == "assistant"]
    
    st.metric("ç”¨æˆ¶è¨Šæ¯æ•¸", len(user_messages))
    st.metric("åŠ©æ‰‹å›æ‡‰æ•¸", len(assistant_messages))
    
    # æ­·å²è¨˜éŒ„å±•é–‹/æ”¶åˆ
    with st.expander("ğŸ“œ æŸ¥çœ‹å°è©±æ­·å²"):
        for i, message in enumerate(st.session_state.messages):
            if message["role"] != "system":
                role_icon = "ğŸ’¬" if message["role"] == "user" else "ğŸ¤–"
                st.text(f"{role_icon} {message['role'].title()}: {message['content'][:100]}{'...' if len(message['content']) > 100 else ''}")

# ä¸»è¦å…§å®¹å€åŸŸ
st.title("ğŸ¤– ç¶²è·¯å®‰å…¨å°ˆå®¶èŠå¤©åŠ©æ‰‹")
st.markdown("æ­¡è¿ä½¿ç”¨ç¶²è·¯å®‰å…¨å°ˆå®¶AIåŠ©æ‰‹ï¼æ‚¨å¯ä»¥è©¢å•ä»»ä½•é—œæ–¼ç¶²è·¯å®‰å…¨çš„å•é¡Œã€‚")

# é¡¯ç¤ºå°è©±æ­·å²ï¼ˆæ’é™¤ç³»çµ±è¨Šæ¯ï¼‰
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        if message["role"] != "system":  # ä¸é¡¯ç¤ºç³»çµ±è¨Šæ¯
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

# ç”¨æˆ¶è¼¸å…¥
if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ..."):
    # æ·»åŠ ç”¨æˆ¶è¨Šæ¯åˆ°å°è©±æ­·å²
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # é¡¯ç¤ºç”¨æˆ¶è¨Šæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ç”Ÿæˆä¸¦é¡¯ç¤ºåŠ©æ‰‹å›æ‡‰
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” æ€è€ƒä¸­..."):
            try:
                # ä½¿ç”¨ç¾æœ‰çš„inferenceå‡½æ•¸
                response = inference(st.session_state.messages)
                st.markdown(response)
                
                # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°å°è©±æ­·å²
                st.session_state.messages.append({"role": "assistant", "content": response})
                
            except Exception as e:
                st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                st.info("è«‹æª¢æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¢ºè¼‰å…¥ï¼Œæˆ–è€…ç¶²è·¯é€£æ¥æ˜¯å¦æ­£å¸¸ã€‚")

# é è…³
st.divider()
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 12px;'>
    ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥åœ¨å´é‚Šæ¬„ç®¡ç†å°è©±è¨­å®šå’ŒæŸ¥çœ‹æ­·å²è¨˜éŒ„<br>
    ğŸš€ ç”± Foundation-Sec-8B-Instruct æ¨¡å‹é©…å‹•
    </div>
    """, 
    unsafe_allow_html=True
)

# æ·»åŠ ä¸€äº›æ¨£å¼
st.markdown("""
<style>
    .stChat > div {
        max-height: 600px;
        overflow-y: auto;
    }
    
    .stTextInput > div > div > input {
        border-radius: 20px;
    }
    
    .stButton > button {
        border-radius: 20px;
        transition: all 0.3s;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
</style>
""", unsafe_allow_html=True)